<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Dataset - The Mabor Book 🔥</title>


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="../highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="../tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->

        <!-- MathJax -->
        <script async="" src="../../../ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "../";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "../searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">The Mabor Book 🔥</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="dataset"><a class="header" href="#dataset">Dataset</a></h1>
<p>At its core, a dataset is a collection of data typically related to a specific analysis or
processing task. The data modality can vary depending on the task, but most datasets primarily
consist of images, texts, audio or videos.</p>
<p>This data source represents an integral part of machine learning to successfully train a model. Thus,
it is essential to provide a convenient and performant API to handle your data. Since this process
varies wildly from one problem to another, it is defined as a trait that should be implemented on
your type. The dataset trait is quite similar to the dataset abstract class in PyTorch:</p>
<pre><code class="language-rust  ignore">pub trait Dataset&lt;I&gt;: Send + Sync {
    fn get(&amp;self, index: usize) -&gt; Option&lt;I&gt;;
    fn len(&amp;self) -&gt; usize;
}</code></pre>
<p>The dataset trait assumes a fixed-length set of items that can be randomly accessed in constant
time. This is a major difference from datasets that use Apache Arrow underneath to improve streaming
performance. Datasets in Mabor don't assume <em>how</em> they are going to be accessed; it's just a
collection of items.</p>
<p>However, you can compose multiple dataset transformations to lazily obtain what you want with zero
pre-processing, so that your training can start instantly!</p>
<h2 id="transformation"><a class="header" href="#transformation">Transformation</a></h2>
<p>Transformations in Mabor are all lazy and modify one or multiple input datasets. The goal of these
transformations is to provide you with the necessary tools so that you can model complex data
distributions.</p>
<div class="table-wrapper"><table><thead><tr><th>Transformation</th><th>Description</th></tr></thead><tbody>
<tr><td><code>SamplerDataset</code></td><td>Samples items from a dataset. This is a convenient way to model a dataset as a probability distribution of a fixed size.</td></tr>
<tr><td><code>ShuffledDataset</code></td><td>Maps each input index to a random index, similar to a dataset sampled without replacement.</td></tr>
<tr><td><code>PartialDataset</code></td><td>Returns a view of the input dataset with a specified range.</td></tr>
<tr><td><code>MapperDataset</code></td><td>Computes a transformation lazily on the input dataset.</td></tr>
<tr><td><code>ComposedDataset</code></td><td>Composes multiple datasets together to create a larger one without copying any data.</td></tr>
<tr><td><code>WindowsDataset</code></td><td>Dataset designed to work with overlapping windows of data extracted from an input dataset.</td></tr>
</tbody></table>
</div>
<p>Let us look at the basic usages of each dataset transform and how they can be composed together.
These transforms are lazy by default except when specified, reducing the need for unnecessary
intermediate allocations and improving performance. The full documentation of each transform can be
found at the <a href="../../../docs/burn/data/dataset/transform/index.html">API reference</a>.</p>
<ul>
<li><strong>SamplerDataset</strong>: This transform can be used to sample items from a dataset with (default) or
without replacement. Transform is initialized with a sampling size which can be bigger or smaller
than the input dataset size. This is particularly useful in cases where we want to checkpoint
larger datasets more often during training and smaller datasets less often as the size of an epoch
is now controlled by the sampling size. Sample usage:</li>
</ul>
<pre><code class="language-rust  ignore">type DbPedia = SqliteDataset&lt;DbPediaItem&gt;;
let dataset: DbPedia = HuggingfaceDatasetLoader::new("dbpedia_14")
        .dataset("train").
        .unwrap();

let dataset = SamplerDataset&lt;DbPedia, DbPediaItem&gt;::new(dataset, 10000);</code></pre>
<ul>
<li><strong>ShuffledDataset</strong>: This transform can be used to shuffle the items of a dataset. Particularly
useful before splitting the raw dataset into train/test splits. Can be initialized with a seed to
ensure reproducibility.</li>
</ul>
<pre><code class="language-rust  ignore">let dataset = ShuffledDataset&lt;DbPedia, DbPediaItem&gt;::with_seed(dataset, 42);</code></pre>
<ul>
<li><strong>PartialDataset</strong>: This transform is useful to return a view of the dataset with specified start
and end indices. Used to create train/val/test splits. In the example below, we show how to chain
ShuffledDataset and PartialDataset to create splits.</li>
</ul>
<pre><code class="language-rust  ignore">// define chained dataset type here for brevity
type PartialData = PartialDataset&lt;ShuffledDataset&lt;DbPedia, DbPediaItem&gt;&gt;;
let len = dataset.len();
let split == "train"; // or "val"/"test"

let data_split = match split {
            "train" =&gt; PartialData::new(dataset, 0, len * 8 / 10), // Get first 80% dataset
            "test" =&gt; PartialData::new(dataset, len * 8 / 10, len), // Take remaining 20%
            _ =&gt; panic!("Invalid split type"),                     // Handle unexpected split types
        };</code></pre>
<ul>
<li>
<p><strong>MapperDataset</strong>: This transform is useful to apply a transformation on each of the items of a
dataset. Particularly useful for normalization of image data when channel means are known.</p>
</li>
<li>
<p><strong>ComposedDataset</strong>: This transform is useful to compose multiple datasets downloaded from
multiple sources (say different HuggingfaceDatasetLoader sources) into a single bigger dataset
which can be sampled from one source.</p>
</li>
<li>
<p><strong>WindowsDataset</strong>: This transform is useful to create overlapping windows of a dataset.
Particularly useful for sequential Time series Data, for example when working with an LSTM.</p>
</li>
</ul>
<h2 id="storage"><a class="header" href="#storage">Storage</a></h2>
<p>There are multiple dataset storage options available for you to choose from. The choice of the
dataset to use should be based on the dataset's size as well as its intended purpose.</p>
<div class="table-wrapper"><table><thead><tr><th>Storage</th><th>Description</th></tr></thead><tbody>
<tr><td><code>InMemDataset</code></td><td>In-memory dataset that uses a vector to store items. Well-suited for smaller datasets.</td></tr>
<tr><td><code>SqliteDataset</code></td><td>Dataset that uses <a href="https://www.sqlite.org/">SQLite</a> to index items that can be saved in a simple SQL database file. Well-suited for larger datasets.</td></tr>
<tr><td><code>DataframeDataset</code></td><td>Dataset that uses <a href="https://www.pola.rs/">Polars</a> dataframe to store and manage data. Well-suited for efficient data manipulation and analysis.</td></tr>
</tbody></table>
</div>
<h2 id="sources"><a class="header" href="#sources">Sources</a></h2>
<p>For now, there are only a couple of dataset sources available with Mabor, but more to come!</p>
<h3 id="hugging-face"><a class="header" href="#hugging-face">Hugging Face</a></h3>
<p>You can easily import any Hugging Face dataset with Mabor. We use SQLite as the storage to avoid
downloading the model each time or starting a Python process. You need to know the format of each
item in the dataset beforehand. Here's an example with the
<a href="https://huggingface.co/datasets/dbpedia_14">dbpedia dataset</a>.</p>
<pre><code class="language-rust  ignore">#[derive(Clone, Debug, serde::Serialize, serde::Deserialize)]
pub struct DbPediaItem {
    pub title: String,
    pub content: String,
    pub label: usize,
}

fn main() {
    let dataset: SqliteDataset&lt;DbPediaItem&gt; = HuggingfaceDatasetLoader::new("dbpedia_14")
        .dataset("train") // The training split.
        .unwrap();
}</code></pre>
<p>We see that items must derive <code>serde::Serialize</code>, <code>serde::Deserialize</code>, <code>Clone</code>, and <code>Debug</code>, but
those are the only requirements.</p>
<h3 id="images"><a class="header" href="#images">Images</a></h3>
<p><code>ImageFolderDataset</code> is a generic vision dataset used to load images from disk. It is currently
available for multi-class and multi-label classification tasks as well as semantic segmentation and object detection tasks.</p>
<pre><code class="language-rust  ignore">// Create an image classification dataset from the root folder,
// where images for each class are stored in their respective folder.
//
// For example:
// root/dog/dog1.png
// root/dog/dog2.png
// ...
// root/cat/cat1.png
let dataset = ImageFolderDataset::new_classification("path/to/dataset/root").unwrap();</code></pre>
<pre><code class="language-rust  ignore">// Create a multi-label image classification dataset from a list of items,
// where each item is a tuple `(image path, labels)`, and a list of classes
// in the dataset.
//
// For example:
let items = vec![
    ("root/dog/dog1.png", vec!["animal".to_string(), "dog".to_string()]),
    ("root/cat/cat1.png", vec!["animal".to_string(), "cat".to_string()]),
];
let dataset = ImageFolderDataset::new_multilabel_classification_with_items(
    items,
    &amp;["animal", "cat", "dog"],
)
.unwrap();</code></pre>
<pre><code class="language-rust  ignore">// Create a segmentation mask dataset from a list of items, where each
// item is a tuple `(image path, mask path)` and a list of classes
// corresponding to the integer values in the mask.
let items = vec![
    (
        "path/to/images/image0.png",
        "path/to/annotations/mask0.png",
    ),
    (
        "path/to/images/image1.png",
        "path/to/annotations/mask1.png",
    ),
    (
        "path/to/images/image2.png",
        "path/to/annotations/mask2.png",
    ),
];
let dataset = ImageFolderDataset::new_segmentation_with_items(
    items,
    &amp;[
        "cat", // 0
        "dog", // 1
        "background", // 2
    ],
)
.unwrap();</code></pre>
<pre><code class="language-rust  ignore">// Create an object detection dataset from a COCO dataset. Currently only
// the import of object detection data (bounding boxes) is supported.
//
// COCO offers separate annotation and image archives for training and
// validation, paths to the unpacked files need to be passed as parameters:

let dataset = ImageFolderDataset::new_coco_detection(
    "/path/to/coco/instances_train2017.json",
    "/path/to/coco/images/train2017"
)
.unwrap();
</code></pre>
<h3 id="comma-separated-values-csv"><a class="header" href="#comma-separated-values-csv">Comma-Separated Values (CSV)</a></h3>
<p>Loading records from a simple CSV file in-memory is simple with the <code>InMemDataset</code>:</p>
<pre><code class="language-rust  ignore">// Build dataset from csv with tab ('\t') delimiter.
// The reader can be configured for your particular file.
let mut rdr = csv::ReaderBuilder::new();
let rdr = rdr.delimiter(b'\t');

let dataset = InMemDataset::from_csv("path/to/csv", rdr).unwrap();</code></pre>
<p>Note that this requires the <code>csv</code> crate.</p>
<p><strong>What about streaming datasets?</strong></p>
<p>There is no streaming dataset API with Mabor, and this is by design! The learner struct will iterate
multiple times over the dataset and only checkpoint when done. You can consider the length of the
dataset as the number of iterations before performing checkpointing and running the validation.
There is nothing stopping you from returning different items even when called with the same <code>index</code>
multiple times.</p>
<h2 id="how-is-the-dataset-used"><a class="header" href="#how-is-the-dataset-used">How Is The Dataset Used?</a></h2>
<p>During training, the dataset is used to access the data samples and, for most use cases in
supervised learning, their corresponding ground-truth labels. Remember that the <code>Dataset</code> trait
implementation is responsible to retrieve the data from its source, usually some sort of data
storage. At this point, the dataset could be naively iterated over to provide the model a single
sample to process at a time, but this is not very efficient.</p>
<p>Instead, we collect multiple samples that the model can process as a <em>batch</em> to fully leverage
modern hardware (e.g., GPUs - which have impressing parallel processing capabilities). Since each
data sample in the dataset can be collected independently, the data loading is typically done in
parallel to further speed things up. In this case, we parallelize the data loading using a
multi-threaded <code>BatchDataLoader</code> to obtain a sequence of items from the <code>Dataset</code> implementation.
Finally, the sequence of items is combined into a batched tensor that can be used as input to a
model with the <code>Batcher</code> trait implementation. Other tensor operations can be performed during this
step to prepare the batch data, as is done <a href="../basic-workflow/data.html">in the basic workflow guide</a>.
The process is illustrated in the figure below for the MNIST dataset.</p>
<img title="Mabor Data Loading Pipeline" alt="Burn Data Loading Pipeline" src="dataset.png">
<p>Although we have conveniently implemented the
<a href="https://github.com/tracel-ai/burn/blob/main/crates/burn-dataset/src/vision/mnist.rs"><code>MnistDataset</code></a>
used in the guide, we'll go over its implementation to demonstrate how the <code>Dataset</code> and <code>Batcher</code>
traits are used.</p>
<p>The <a href="http://yann.lecun.com/exdb/mnist/">MNIST dataset</a> of handwritten digits has a training set of
60,000 examples and a test set of 10,000 examples. A single item in the dataset is represented by a
\(28 \times 28\) pixels black-and-white image (stored as raw bytes) with its corresponding label
(a digit between \(0\) and \(9\)). This is defined by the <code>MnistItemRaw</code> struct.</p>
<pre><code class="language-rust  ignore"><span class="boring">#[derive(Deserialize, Debug, Clone)]
</span>struct MnistItemRaw {
    pub image_bytes: Vec&lt;u8&gt;,
    pub label: u8,
}</code></pre>
<p>With single-channel images of such low resolution, the entire training and test sets can be loaded
in memory at once. Therefore, we leverage the already existing <code>InMemDataset</code> to retrieve the raw
images and labels data. At this point, the image data is still just a bunch of bytes, but we want to
retrieve the <em>structured</em> image data in its intended form. For that, we can define a <code>MapperDataset</code>
that transforms the raw image bytes to a 2D array image (which we convert to float while we're at
it).</p>
<pre><code class="language-rust  ignore">const WIDTH: usize = 28;
const HEIGHT: usize = 28;

<span class="boring">/// MNIST item.
</span><span class="boring">#[derive(Deserialize, Serialize, Debug, Clone)]
</span>pub struct MnistItem {
    /// Image as a 2D array of floats.
    pub image: [[f32; WIDTH]; HEIGHT],

    /// Label of the image.
    pub label: u8,
}

struct BytesToImage;

impl Mapper&lt;MnistItemRaw, MnistItem&gt; for BytesToImage {
    /// Convert a raw MNIST item (image bytes) to a MNIST item (2D array image).
    fn map(&amp;self, item: &amp;MnistItemRaw) -&gt; MnistItem {
        // Ensure the image dimensions are correct.
        debug_assert_eq!(item.image_bytes.len(), WIDTH * HEIGHT);

        // Convert the image to a 2D array of floats.
        let mut image_array = [[0f32; WIDTH]; HEIGHT];
        for (i, pixel) in item.image_bytes.iter().enumerate() {
            let x = i % WIDTH;
            let y = i / HEIGHT;
            image_array[y][x] = *pixel as f32;
        }

        MnistItem {
            image: image_array,
            label: item.label,
        }
    }
}

type MappedDataset = MapperDataset&lt;InMemDataset&lt;MnistItemRaw&gt;, BytesToImage, MnistItemRaw&gt;;

<span class="boring">/// The MNIST dataset consists of 70,000 28x28 black-and-white images in 10 classes (one for each digits), with 7,000
</span><span class="boring">/// images per class. There are 60,000 training images and 10,000 test images.
</span><span class="boring">///
</span><span class="boring">/// The data is downloaded from the web from the [CVDF mirror](https://github.com/cvdfoundation/mnist).
</span>pub struct MnistDataset {
    dataset: MappedDataset,
}</code></pre>
<p>To construct the <code>MnistDataset</code>, the data source must be parsed into the expected <code>MappedDataset</code>
type. Since both the train and test sets use the same file format, we can separate the functionality
to load the <code>train()</code> and <code>test()</code> dataset.</p>
<pre><code class="language-rust  ignore">
impl MnistDataset {
    /// Creates a new train dataset.
    pub fn train() -&gt; Self {
        Self::new("train")
    }

    /// Creates a new test dataset.
    pub fn test() -&gt; Self {
        Self::new("test")
    }

    fn new(split: &amp;str) -&gt; Self {
        // Download dataset
        let root = MnistDataset::download(split);

        // Parse data as vector of images bytes and vector of labels
        let images: Vec&lt;Vec&lt;u8&gt;&gt; = MnistDataset::read_images(&amp;root, split);
        let labels: Vec&lt;u8&gt; = MnistDataset::read_labels(&amp;root, split);

        // Collect as vector of MnistItemRaw
        let items: Vec&lt;_&gt; = images
            .into_iter()
            .zip(labels)
            .map(|(image_bytes, label)| MnistItemRaw { image_bytes, label })
            .collect();

        // Create the MapperDataset for InMemDataset&lt;MnistItemRaw&gt; to transform
        // items (MnistItemRaw -&gt; MnistItem)
        let dataset = InMemDataset::new(items);
        let dataset = MapperDataset::new(dataset, BytesToImage);

        Self { dataset }
    }

<span class="boring">   /// Download the MNIST dataset files from the web.
</span><span class="boring">   /// Panics if the download cannot be completed or the content of the file cannot be written to disk.
</span><span class="boring">   fn download(split: &amp;str) -&gt; PathBuf {
</span><span class="boring">       // Dataset files are stored un the mabor-dataset cache directory
</span><span class="boring">       let cache_dir = dirs::home_dir()
</span><span class="boring">           .expect("Could not get home directory")
</span><span class="boring">           .join(".cache")
</span><span class="boring">           .join("mabor-dataset");
</span><span class="boring">       let split_dir = cache_dir.join("mnist").join(split);
</span><span class="boring">
</span><span class="boring">       if !split_dir.exists() {
</span><span class="boring">           create_dir_all(&amp;split_dir).expect("Failed to create base directory");
</span><span class="boring">       }
</span><span class="boring">
</span><span class="boring">       // Download split files
</span><span class="boring">       match split {
</span><span class="boring">           "train" =&gt; {
</span><span class="boring">               MnistDataset::download_file(TRAIN_IMAGES, &amp;split_dir);
</span><span class="boring">               MnistDataset::download_file(TRAIN_LABELS, &amp;split_dir);
</span><span class="boring">           }
</span><span class="boring">           "test" =&gt; {
</span><span class="boring">               MnistDataset::download_file(TEST_IMAGES, &amp;split_dir);
</span><span class="boring">               MnistDataset::download_file(TEST_LABELS, &amp;split_dir);
</span><span class="boring">           }
</span><span class="boring">           _ =&gt; panic!("Invalid split specified {}", split),
</span><span class="boring">       };
</span><span class="boring">
</span><span class="boring">       split_dir
</span><span class="boring">   }
</span><span class="boring">
</span><span class="boring">   /// Download a file from the MNIST dataset URL to the destination directory.
</span><span class="boring">   /// File download progress is reported with the help of a [progress bar](indicatif).
</span><span class="boring">   fn download_file&lt;P: AsRef&lt;Path&gt;&gt;(name: &amp;str, dest_dir: &amp;P) -&gt; PathBuf {
</span><span class="boring">       // Output file name
</span><span class="boring">       let file_name = dest_dir.as_ref().join(name);
</span><span class="boring">
</span><span class="boring">       if !file_name.exists() {
</span><span class="boring">           // Download gzip file
</span><span class="boring">           let bytes = download_file_as_bytes(&amp;format!("{URL}{name}.gz"), name);
</span><span class="boring">
</span><span class="boring">           // Create file to write the downloaded content to
</span><span class="boring">           let mut output_file = File::create(&amp;file_name).unwrap();
</span><span class="boring">
</span><span class="boring">           // Decode gzip file content and write to disk
</span><span class="boring">           let mut gz_buffer = GzDecoder::new(&amp;bytes[..]);
</span><span class="boring">           std::io::copy(&amp;mut gz_buffer, &amp;mut output_file).unwrap();
</span><span class="boring">       }
</span><span class="boring">
</span><span class="boring">       file_name
</span><span class="boring">   }
</span><span class="boring">
</span><span class="boring">   /// Read images at the provided path for the specified split.
</span><span class="boring">   /// Each image is a vector of bytes.
</span><span class="boring">   fn read_images&lt;P: AsRef&lt;Path&gt;&gt;(root: &amp;P, split: &amp;str) -&gt; Vec&lt;Vec&lt;u8&gt;&gt; {
</span><span class="boring">       let file_name = if split == "train" {
</span><span class="boring">           TRAIN_IMAGES
</span><span class="boring">       } else {
</span><span class="boring">           TEST_IMAGES
</span><span class="boring">       };
</span><span class="boring">       let file_name = root.as_ref().join(file_name);
</span><span class="boring">
</span><span class="boring">       // Read number of images from 16-byte header metadata
</span><span class="boring">       let mut f = File::open(file_name).unwrap();
</span><span class="boring">       let mut buf = [0u8; 4];
</span><span class="boring">       let _ = f.seek(SeekFrom::Start(4)).unwrap();
</span><span class="boring">       f.read_exact(&amp;mut buf)
</span><span class="boring">           .expect("Should be able to read image file header");
</span><span class="boring">       let size = u32::from_be_bytes(buf);
</span><span class="boring">
</span><span class="boring">       let mut buf_images: Vec&lt;u8&gt; = vec![0u8; WIDTH * HEIGHT * (size as usize)];
</span><span class="boring">       let _ = f.seek(SeekFrom::Start(16)).unwrap();
</span><span class="boring">       f.read_exact(&amp;mut buf_images)
</span><span class="boring">           .expect("Should be able to read image file header");
</span><span class="boring">
</span><span class="boring">       buf_images
</span><span class="boring">           .chunks(WIDTH * HEIGHT)
</span><span class="boring">           .map(|chunk| chunk.to_vec())
</span><span class="boring">           .collect()
</span><span class="boring">   }
</span><span class="boring">
</span><span class="boring">   /// Read labels at the provided path for the specified split.
</span><span class="boring">   fn read_labels&lt;P: AsRef&lt;Path&gt;&gt;(root: &amp;P, split: &amp;str) -&gt; Vec&lt;u8&gt; {
</span><span class="boring">       let file_name = if split == "train" {
</span><span class="boring">           TRAIN_LABELS
</span><span class="boring">       } else {
</span><span class="boring">           TEST_LABELS
</span><span class="boring">       };
</span><span class="boring">       let file_name = root.as_ref().join(file_name);
</span><span class="boring">
</span><span class="boring">       // Read number of labels from 8-byte header metadata
</span><span class="boring">       let mut f = File::open(file_name).unwrap();
</span><span class="boring">       let mut buf = [0u8; 4];
</span><span class="boring">       let _ = f.seek(SeekFrom::Start(4)).unwrap();
</span><span class="boring">       f.read_exact(&amp;mut buf)
</span><span class="boring">           .expect("Should be able to read label file header");
</span><span class="boring">       let size = u32::from_be_bytes(buf);
</span><span class="boring">
</span><span class="boring">       let mut buf_labels: Vec&lt;u8&gt; = vec![0u8; size as usize];
</span><span class="boring">       let _ = f.seek(SeekFrom::Start(8)).unwrap();
</span><span class="boring">       f.read_exact(&amp;mut buf_labels)
</span><span class="boring">           .expect("Should be able to read labels from file");
</span><span class="boring">
</span><span class="boring">       buf_labels
</span><span class="boring">   }
</span>}</code></pre>
<p>Since the <code>MnistDataset</code> simply wraps a <code>MapperDataset</code> instance with <code>InMemDataset</code>, we can easily
implement the <code>Dataset</code> trait.</p>
<pre><code class="language-rust  ignore">impl Dataset&lt;MnistItem&gt; for MnistDataset {
    fn get(&amp;self, index: usize) -&gt; Option&lt;MnistItem&gt; {
        self.dataset.get(index)
    }

    fn len(&amp;self) -&gt; usize {
        self.dataset.len()
    }
}</code></pre>
<p>The only thing missing now is the <code>Batcher</code>, which we already went over
<a href="../basic-workflow/data.html">in the basic workflow guide</a>. The <code>Batcher</code> takes a list of <code>MnistItem</code>
retrieved by the dataloader as input and returns a batch of images as a 3D tensor along with their
targets.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="record.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../custom-training-loop.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="record.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../custom-training-loop.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->



    </div>
    </body>
</html>
