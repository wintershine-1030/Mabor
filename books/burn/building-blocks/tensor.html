<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Tensor - The Mabor Book 🔥</title>


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="../highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="../tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->

        <!-- MathJax -->
        <script async="" src="../../../ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "../";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "../searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">The Mabor Book 🔥</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="tensor"><a class="header" href="#tensor">Tensor</a></h1>
<p>As previously explained in the <a href="../basic-workflow/model.html">model section</a>, the Tensor struct has 3
generic arguments: the backend B, the dimensionality D, and the data type.</p>
<pre><code class="language-rust   ignore">Tensor&lt;B, D&gt;           // Float tensor (default)
Tensor&lt;B, D, Float&gt;    // Explicit float tensor
Tensor&lt;B, D, Int&gt;      // Int tensor
Tensor&lt;B, D, Bool&gt;     // Bool tensor</code></pre>
<p>Note that the specific element types used for <code>Float</code>, <code>Int</code>, and <code>Bool</code> tensors are defined by
backend implementations.</p>
<p>Mabor Tensors are defined by the number of dimensions D in its declaration as opposed to its shape.
The actual shape of the tensor is inferred from its initialization. For example, a Tensor of size
(5,) is initialized as below:</p>
<pre><code class="language-rust  ignore">let floats = [1.0, 2.0, 3.0, 4.0, 5.0];

// Get the default device
let device = Default::default();

// correct: Tensor is 1-Dimensional with 5 elements
let tensor_1 = Tensor::&lt;Backend, 1&gt;::from_floats(floats, &amp;device);

// incorrect: let tensor_1 = Tensor::&lt;Backend, 5&gt;::from_floats(floats, &amp;device);
// this will lead to an error and is for creating a 5-D tensor</code></pre>
<h3 id="initialization"><a class="header" href="#initialization">Initialization</a></h3>
<p>Mabor Tensors are primarily initialized using the <code>from_data()</code> method which takes the <code>TensorData</code>
struct as input. The <code>TensorData</code> struct has two public fields: <code>shape</code> and <code>dtype</code>. The <code>value</code>,
now stored as bytes, is private but can be accessed via any of the following methods: <code>as_slice</code>,
<code>as_mut_slice</code>, <code>to_vec</code> and <code>iter</code>. To retrieve the data from a tensor, the method <code>.to_data()</code>
should be employed when intending to reuse the tensor afterward. Alternatively, <code>.into_data()</code> is
recommended for one-time use. Let's look at a couple of examples for initializing a tensor from
different inputs.</p>
<pre><code class="language-rust  ignore">
// Initialization from a given Backend (Wgpu)
let tensor_1 = Tensor::&lt;Wgpu, 1&gt;::from_data([1.0, 2.0, 3.0], &amp;device);

// Initialization from a generic Backend
let tensor_2 = Tensor::&lt;Backend, 1&gt;::from_data(TensorData::from([1.0, 2.0, 3.0]), &amp;device);

// Initialization using from_floats (Recommended for f32 ElementType)
// Will be converted to TensorData internally.
let tensor_3 = Tensor::&lt;Backend, 1&gt;::from_floats([1.0, 2.0, 3.0], &amp;device);

// Initialization of Int Tensor from array slices
let arr: [i32; 6] = [1, 2, 3, 4, 5, 6];
let tensor_4 = Tensor::&lt;Backend, 1, Int&gt;::from_data(TensorData::from(&amp;arr[0..3]), &amp;device);

// Initialization from a custom type

struct BodyMetrics {
    age: i8,
    height: i16,
    weight: f32
}

let bmi = BodyMetrics{
        age: 25,
        height: 180,
        weight: 80.0
    };
let data  = TensorData::from([bmi.age as f32, bmi.height as f32, bmi.weight]);
let tensor_5 = Tensor::&lt;Backend, 1&gt;::from_data(data, &amp;device);
</code></pre>
<h2 id="ownership-and-cloning"><a class="header" href="#ownership-and-cloning">Ownership and Cloning</a></h2>
<p>Almost all Mabor operations take ownership of the input tensors. Therefore, reusing a tensor multiple
times will necessitate cloning it. Let's look at an example to understand the ownership rules and
cloning better. Suppose we want to do a simple min-max normalization of an input tensor.</p>
<pre><code class="language-rust  ignore">let input = Tensor::&lt;Wgpu, 1&gt;::from_floats([1.0, 2.0, 3.0, 4.0], &amp;device);
let min = input.min();
let max = input.max();
let input = (input - min).div(max - min);</code></pre>
<p>With PyTorch tensors, the above code would work as expected. However, Rust's strict ownership rules
will give an error and prevent using the input tensor after the first <code>.min()</code> operation. The
ownership of the input tensor is transferred to the variable <code>min</code> and the input tensor is no longer
available for further operations. Mabor Tensors like most complex primitives do not implement the
<code>Copy</code> trait and therefore have to be cloned explicitly. Now let's rewrite a working example of
doing min-max normalization with cloning.</p>
<pre><code class="language-rust  ignore">let input = Tensor::&lt;Wgpu, 1&gt;::from_floats([1.0, 2.0, 3.0, 4.0], &amp;device);
let min = input.clone().min();
let max = input.clone().max();
let input = (input.clone() - min.clone()).div(max - min);
println!("{}", input.to_data());// Success: [0.0, 0.33333334, 0.6666667, 1.0]

// Notice that max, min have been moved in last operation so
// the below print will give an error.
// If we want to use them for further operations,
// they will need to be cloned in similar fashion.
// println!("{:?}", min.to_data());</code></pre>
<p>We don't need to be worried about memory overhead because with cloning, the tensor's buffer isn't
copied, and only a reference to it is increased. This makes it possible to determine exactly how
many times a tensor is used, which is very convenient for reusing tensor buffers or even fusing
operations into a single kernel (<a href="https://burn.dev/docs/burn_fusion/index.htmls">mabor-fusion</a>). For
that reason, we don't provide explicit inplace operations. If a tensor is used only one time,
inplace operations will always be used when available.</p>
<h2 id="tensor-operations"><a class="header" href="#tensor-operations">Tensor Operations</a></h2>
<p>Normally with PyTorch, explicit inplace operations aren't supported during the backward pass, making
them useful only for data preprocessing or inference-only model implementations. With Mabor, you can
focus more on <em>what</em> the model should do, rather than on <em>how</em> to do it. We take the responsibility
of making your code run as fast as possible during training as well as inference. The same
principles apply to broadcasting; all operations support broadcasting unless specified otherwise.</p>
<p>Here, we provide a list of all supported operations along with their PyTorch equivalents. Note that
for the sake of simplicity, we ignore type signatures. For more details, refer to the
<a href="https://docs.rs/burn/latest/burn/tensor/struct.Tensor.html">full documentation</a>.</p>
<h3 id="basic-operations"><a class="header" href="#basic-operations">Basic Operations</a></h3>
<p>Those operations are available for all tensor kinds: <code>Int</code>, <code>Float</code>, and <code>Bool</code>.</p>
<div class="table-wrapper"><table><thead><tr><th>Mabor</th><th>PyTorch Equivalent</th></tr></thead><tbody>
<tr><td><code>Tensor::cat(tensors, dim)</code></td><td><code>torch.cat(tensors, dim)</code></td></tr>
<tr><td><code>Tensor::empty(shape, device)</code></td><td><code>torch.empty(shape, device=device)</code></td></tr>
<tr><td><code>Tensor::from_primitive(primitive)</code></td><td>N/A</td></tr>
<tr><td><code>Tensor::stack(tensors, dim)</code></td><td><code>torch.stack(tensors, dim)</code></td></tr>
<tr><td><code>tensor.all()</code></td><td><code>tensor.all()</code></td></tr>
<tr><td><code>tensor.all_dim(dim)</code></td><td><code>tensor.all(dim)</code></td></tr>
<tr><td><code>tensor.any()</code></td><td><code>tensor.any()</code></td></tr>
<tr><td><code>tensor.any_dim(dim)</code></td><td><code>tensor.any(dim)</code></td></tr>
<tr><td><code>tensor.chunk(num_chunks, dim)</code></td><td><code>tensor.chunk(num_chunks, dim)</code></td></tr>
<tr><td><code>tensor.split(split_size, dim)</code></td><td><code>tensor.split(split_size, dim)</code></td></tr>
<tr><td><code>tensor.split_with_sizes(split_sizes, dim)</code></td><td><code>tensor.split([split_sizes], dim)</code></td></tr>
<tr><td><code>tensor.device()</code></td><td><code>tensor.device</code></td></tr>
<tr><td><code>tensor.dtype()</code></td><td><code>tensor.dtype</code></td></tr>
<tr><td><code>tensor.dims()</code></td><td><code>tensor.size()</code></td></tr>
<tr><td><code>tensor.equal(other)</code></td><td><code>x == y</code></td></tr>
<tr><td><code>tensor.expand(shape)</code></td><td><code>tensor.expand(shape)</code></td></tr>
<tr><td><code>tensor.flatten(start_dim, end_dim)</code></td><td><code>tensor.flatten(start_dim, end_dim)</code></td></tr>
<tr><td><code>tensor.flip(axes)</code></td><td><code>tensor.flip(axes)</code></td></tr>
<tr><td><code>tensor.into_data()</code></td><td>N/A</td></tr>
<tr><td><code>tensor.into_primitive()</code></td><td>N/A</td></tr>
<tr><td><code>tensor.into_scalar()</code></td><td><code>tensor.item()</code></td></tr>
<tr><td><code>tensor.narrow(dim, start, length)</code></td><td><code>tensor.narrow(dim, start, length)</code></td></tr>
<tr><td><code>tensor.not_equal(other)</code></td><td><code>x != y</code></td></tr>
<tr><td><code>tensor.permute(axes)</code></td><td><code>tensor.permute(axes)</code></td></tr>
<tr><td><code>tensor.movedim(src, dst)</code></td><td><code>tensor.movedim(src, dst)</code></td></tr>
<tr><td><code>tensor.repeat_dim(dim, times)</code></td><td><code>tensor.repeat(*[times if i == dim else 1 for i in range(tensor.dim())])</code></td></tr>
<tr><td><code>tensor.repeat(sizes)</code></td><td><code>tensor.repeat(sizes)</code></td></tr>
<tr><td><code>tensor.reshape(shape)</code></td><td><code>tensor.view(shape)</code></td></tr>
<tr><td><code>tensor.roll(shfts, dims)</code></td><td><code>tensor.roll(shifts, dims)</code></td></tr>
<tr><td><code>tensor.roll_dim(shift, dim)</code></td><td><code>tensor.roll([shift], [dim])</code></td></tr>
<tr><td><code>tensor.shape()</code></td><td><code>tensor.shape</code></td></tr>
<tr><td><code>tensor.slice(ranges)</code></td><td><code>tensor[(*ranges,)]</code></td></tr>
<tr><td><code>tensor.slice_assign(ranges, values)</code></td><td><code>tensor[(*ranges,)] = values</code></td></tr>
<tr><td><code>tensor.slice_fill(ranges, value)</code></td><td><code>tensor[(*ranges,)] = value</code></td></tr>
<tr><td><code>tensor.slice_dim(dim, range)</code></td><td>N/A</td></tr>
<tr><td><code>tensor.squeeze(dim)</code></td><td><code>tensor.squeeze(dim)</code></td></tr>
<tr><td><code>tensor.swap_dims(dim1, dim2)</code></td><td><code>tensor.transpose(dim1, dim2)</code></td></tr>
<tr><td><code>tensor.to_data()</code></td><td>N/A</td></tr>
<tr><td><code>tensor.to_device(device)</code></td><td><code>tensor.to(device)</code></td></tr>
<tr><td><code>tensor.transpose()</code></td><td><code>tensor.T</code></td></tr>
<tr><td><code>tensor.unsqueeze()</code></td><td><code>tensor.unsqueeze(0)</code></td></tr>
<tr><td><code>tensor.unsqueeze_dim(dim)</code></td><td><code>tensor.unsqueeze(dim)</code></td></tr>
<tr><td><code>tensor.unsqueeze_dims(dims)</code></td><td>N/A</td></tr>
</tbody></table>
</div>
<h3 id="numeric-operations"><a class="header" href="#numeric-operations">Numeric Operations</a></h3>
<p>Those operations are available for numeric tensor kinds: <code>Float</code> and <code>Int</code>.</p>
<div class="table-wrapper"><table><thead><tr><th>Mabor</th><th>PyTorch Equivalent</th></tr></thead><tbody>
<tr><td><code>Tensor::eye(size, device)</code></td><td><code>torch.eye(size, device=device)</code></td></tr>
<tr><td><code>Tensor::full(shape, fill_value, device)</code></td><td><code>torch.full(shape, fill_value, device=device)</code></td></tr>
<tr><td><code>Tensor::ones(shape, device)</code></td><td><code>torch.ones(shape, device=device)</code></td></tr>
<tr><td><code>Tensor::zeros(shape, device)</code></td><td><code>torch.zeros(shape, device=device)</code></td></tr>
<tr><td><code>tensor.abs()</code></td><td><code>torch.abs(tensor)</code></td></tr>
<tr><td><code>tensor.add(other)</code> or <code>tensor + other</code></td><td><code>tensor + other</code></td></tr>
<tr><td><code>tensor.add_scalar(scalar)</code> or <code>tensor + scalar</code></td><td><code>tensor + scalar</code></td></tr>
<tr><td><code>tensor.all_close(other, atol, rtol)</code></td><td><code>torch.allclose(tensor, other, atol, rtol)</code></td></tr>
<tr><td><code>tensor.argmax(dim)</code></td><td><code>tensor.argmax(dim)</code></td></tr>
<tr><td><code>tensor.argmin(dim)</code></td><td><code>tensor.argmin(dim)</code></td></tr>
<tr><td><code>tensor.argsort(dim)</code></td><td><code>tensor.argsort(dim)</code></td></tr>
<tr><td><code>tensor.argsort_descending(dim)</code></td><td><code>tensor.argsort(dim, descending=True)</code></td></tr>
<tr><td><code>tensor.bool()</code></td><td><code>tensor.bool()</code></td></tr>
<tr><td><code>tensor.clamp(min, max)</code></td><td><code>torch.clamp(tensor, min=min, max=max)</code></td></tr>
<tr><td><code>tensor.clamp_max(max)</code></td><td><code>torch.clamp(tensor, max=max)</code></td></tr>
<tr><td><code>tensor.clamp_min(min)</code></td><td><code>torch.clamp(tensor, min=min)</code></td></tr>
<tr><td><code>tensor.contains_nan()</code></td><td>N/A</td></tr>
<tr><td><code>tensor.div(other)</code> or <code>tensor / other</code></td><td><code>tensor / other</code></td></tr>
<tr><td><code>tensor.div_scalar(scalar)</code> or <code>tensor / scalar</code></td><td><code>tensor / scalar</code></td></tr>
<tr><td><code>tensor.equal_elem(other)</code></td><td><code>tensor.eq(other)</code></td></tr>
<tr><td><code>tensor.full_like(fill_value)</code></td><td>`torch.full_like(tensor, fill_value)</td></tr>
<tr><td><code>tensor.gather(dim, indices)</code></td><td><code>torch.gather(tensor, dim, indices)</code></td></tr>
<tr><td><code>tensor.greater(other)</code></td><td><code>tensor.gt(other)</code></td></tr>
<tr><td><code>tensor.greater_elem(scalar)</code></td><td><code>tensor.gt(scalar)</code></td></tr>
<tr><td><code>tensor.greater_equal(other)</code></td><td><code>tensor.ge(other)</code></td></tr>
<tr><td><code>tensor.greater_equal_elem(scalar)</code></td><td><code>tensor.ge(scalar)</code></td></tr>
<tr><td><code>tensor.lower(other)</code></td><td><code>tensor.lt(other)</code></td></tr>
<tr><td><code>tensor.lower_elem(scalar)</code></td><td><code>tensor.lt(scalar)</code></td></tr>
<tr><td><code>tensor.lower_equal(other)</code></td><td><code>tensor.le(other)</code></td></tr>
<tr><td><code>tensor.lower_equal_elem(scalar)</code></td><td><code>tensor.le(scalar)</code></td></tr>
<tr><td><code>tensor.mask_fill(mask, value)</code></td><td><code>tensor.masked_fill(mask, value)</code></td></tr>
<tr><td><code>tensor.mask_where(mask, value_tensor)</code></td><td><code>torch.where(mask, value_tensor, tensor)</code></td></tr>
<tr><td><code>tensor.max()</code></td><td><code>tensor.max()</code></td></tr>
<tr><td><code>tensor.max_abs()</code></td><td><code>tensor.abs().max()</code></td></tr>
<tr><td><code>tensor.max_abs_dim(dim)</code></td><td><code>tensor.abs().max(dim, keepdim=True)</code></td></tr>
<tr><td><code>tensor.max_dim(dim)</code></td><td><code>tensor.max(dim, keepdim=True)</code></td></tr>
<tr><td><code>tensor.max_dim_with_indices(dim)</code></td><td>N/A</td></tr>
<tr><td><code>tensor.max_pair(other)</code></td><td><code>torch.Tensor.max(a,b)</code></td></tr>
<tr><td><code>tensor.mean()</code></td><td><code>tensor.mean()</code></td></tr>
<tr><td><code>tensor.mean_dim(dim)</code></td><td><code>tensor.mean(dim, keepdim=True)</code></td></tr>
<tr><td><code>tensor.min()</code></td><td><code>tensor.min()</code></td></tr>
<tr><td><code>tensor.min_dim(dim)</code></td><td><code>tensor.min(dim, keepdim=True)</code></td></tr>
<tr><td><code>tensor.min_dim_with_indices(dim)</code></td><td>N/A</td></tr>
<tr><td><code>tensor.min_pair(other)</code></td><td><code>torch.Tensor.min(a,b)</code></td></tr>
<tr><td><code>tensor.mul(other)</code> or <code>tensor * other</code></td><td><code>tensor * other</code></td></tr>
<tr><td><code>tensor.mul_scalar(scalar)</code> or <code>tensor * scalar</code></td><td><code>tensor * scalar</code></td></tr>
<tr><td><code>tensor.neg()</code> or <code>-tensor</code></td><td><code>-tensor</code></td></tr>
<tr><td><code>tensor.not_equal_elem(scalar)</code></td><td><code>tensor.ne(scalar)</code></td></tr>
<tr><td><code>tensor.ones_like()</code></td><td><code>torch.ones_like(tensor)</code></td></tr>
<tr><td><code>tensor.one_hot(num_classes)</code></td><td><code>torch.nn.functional.one_hot</code></td></tr>
<tr><td><code>tensor.one_hot_fill(num_classes, on_value, off_value, axis)</code></td><td>N/A</td></tr>
<tr><td><code>tensor.pad(pads, value)</code></td><td><code>torch.nn.functional.pad(input, pad, value)</code></td></tr>
<tr><td><code>tensor.powf(other)</code> or <code>tensor.powi(intother)</code></td><td><code>tensor.pow(other)</code></td></tr>
<tr><td><code>tensor.powf_scalar(scalar)</code> or <code>tensor.powi_scalar(intscalar)</code></td><td><code>tensor.pow(scalar)</code></td></tr>
<tr><td><code>tensor.prod()</code></td><td><code>tensor.prod()</code></td></tr>
<tr><td><code>tensor.prod_dim(dim)</code></td><td><code>tensor.prod(dim, keepdim=True)</code></td></tr>
<tr><td><code>tensor.rem(other)</code> or <code>tensor % other</code></td><td><code>tensor % other</code></td></tr>
<tr><td><code>tensor.scatter(dim, indices, values)</code></td><td><code>tensor.scatter_add(dim, indices, values)</code></td></tr>
<tr><td><code>tensor.select(dim, indices)</code></td><td><code>tensor.index_select(dim, indices)</code></td></tr>
<tr><td><code>tensor.select_assign(dim, indices, values)</code></td><td>N/A</td></tr>
<tr><td><code>tensor.sign()</code></td><td><code>tensor.sign()</code></td></tr>
<tr><td><code>tensor.sort(dim)</code></td><td><code>tensor.sort(dim).values</code></td></tr>
<tr><td><code>tensor.sort_descending(dim)</code></td><td><code>tensor.sort(dim, descending=True).values</code></td></tr>
<tr><td><code>tensor.sort_descending_with_indices(dim)</code></td><td><code>tensor.sort(dim, descending=True)</code></td></tr>
<tr><td><code>tensor.sort_with_indices(dim)</code></td><td><code>tensor.sort(dim)</code></td></tr>
<tr><td><code>tensor.sub(other)</code> or <code>tensor - other</code></td><td><code>tensor - other</code></td></tr>
<tr><td><code>tensor.sub_scalar(scalar)</code> or <code>tensor - scalar</code></td><td><code>tensor - scalar</code></td></tr>
<tr><td><code>scalar - tensor</code></td><td><code>scalar - tensor</code></td></tr>
<tr><td><code>tensor.sum()</code></td><td><code>tensor.sum()</code></td></tr>
<tr><td><code>tensor.sum_dim(dim)</code></td><td><code>tensor.sum(dim, keepdim=True)</code></td></tr>
<tr><td><code>tensor.topk(k, dim)</code></td><td><code>tensor.topk(k, dim).values</code></td></tr>
<tr><td><code>tensor.topk_with_indices(k, dim)</code></td><td><code>tensor.topk(k, dim)</code></td></tr>
<tr><td><code>tensor.tril(diagonal)</code></td><td><code>torch.tril(tensor, diagonal)</code></td></tr>
<tr><td><code>tensor.triu(diagonal)</code></td><td><code>torch.triu(tensor, diagonal)</code></td></tr>
<tr><td><code>tensor.zeros_like()</code></td><td><code>torch.zeros_like(tensor)</code></td></tr>
</tbody></table>
</div>
<h3 id="float-operations"><a class="header" href="#float-operations">Float Operations</a></h3>
<p>Those operations are only available for <code>Float</code> tensors.</p>
<div class="table-wrapper"><table><thead><tr><th>Mabor API</th><th>PyTorch Equivalent</th></tr></thead><tbody>
<tr><td><code>tensor.cast(dtype)</code></td><td><code>tensor.to(dtype)</code></td></tr>
<tr><td><code>tensor.ceil()</code></td><td><code>tensor.ceil()</code></td></tr>
<tr><td><code>tensor.cos()</code></td><td><code>tensor.cos()</code></td></tr>
<tr><td><code>tensor.cosh()</code></td><td><code>tensor.cosh()</code></td></tr>
<tr><td><code>tensor.erf()</code></td><td><code>tensor.erf()</code></td></tr>
<tr><td><code>tensor.exp()</code></td><td><code>tensor.exp()</code></td></tr>
<tr><td><code>tensor.floor()</code></td><td><code>tensor.floor()</code></td></tr>
<tr><td><code>tensor.from_floats(floats, device)</code></td><td>N/A</td></tr>
<tr><td><code>tensor.from_full_precision(tensor)</code></td><td>N/A</td></tr>
<tr><td><code>tensor.int()</code></td><td>Similar to <code>tensor.to(torch.long)</code></td></tr>
<tr><td><code>tensor.is_close(other, atol, rtol)</code></td><td><code>torch.isclose(tensor, other, atol, rtol)</code></td></tr>
<tr><td><code>tensor.is_finite()</code></td><td><code>torch.isfinite(tensor)</code></td></tr>
<tr><td><code>tensor.is_inf()</code></td><td><code>torch.isinf(tensor)</code></td></tr>
<tr><td><code>tensor.is_nan()</code></td><td><code>torch.isnan(tensor)</code></td></tr>
<tr><td><code>tensor.log()</code></td><td><code>tensor.log()</code></td></tr>
<tr><td><code>tensor.log1p()</code></td><td><code>tensor.log1p()</code></td></tr>
<tr><td><code>tensor.matmul(other)</code></td><td><code>tensor.matmul(other)</code></td></tr>
<tr><td><code>tensor.random(shape, distribution, device)</code></td><td>N/A</td></tr>
<tr><td><code>tensor.random_like(distribution)</code></td><td><code>torch.rand_like()</code> only uniform</td></tr>
<tr><td><code>tensor.recip()</code> or <code>1.0 / tensor</code></td><td><code>tensor.reciprocal()</code> or <code>1.0 / tensor</code></td></tr>
<tr><td><code>tensor.round()</code></td><td><code>tensor.round()</code></td></tr>
<tr><td><code>tensor.sin()</code></td><td><code>tensor.sin()</code></td></tr>
<tr><td><code>tensor.sinh()</code></td><td><code>tensor.sinh()</code></td></tr>
<tr><td><code>tensor.sqrt()</code></td><td><code>tensor.sqrt()</code></td></tr>
<tr><td><code>tensor.tan()</code></td><td><code>tensor.tan()</code></td></tr>
<tr><td><code>tensor.tanh()</code></td><td><code>tensor.tanh()</code></td></tr>
<tr><td><code>tensor.to_full_precision()</code></td><td><code>tensor.to(torch.float)</code></td></tr>
<tr><td><code>tensor.var(dim)</code></td><td><code>tensor.var(dim)</code></td></tr>
<tr><td><code>tensor.var_bias(dim)</code></td><td>N/A</td></tr>
<tr><td><code>tensor.var_mean(dim)</code></td><td>N/A</td></tr>
<tr><td><code>tensor.var_mean_bias(dim)</code></td><td>N/A</td></tr>
</tbody></table>
</div>
<h3 id="int-operations"><a class="header" href="#int-operations">Int Operations</a></h3>
<p>Those operations are only available for <code>Int</code> tensors.</p>
<div class="table-wrapper"><table><thead><tr><th>Mabor API</th><th>PyTorch Equivalent</th></tr></thead><tbody>
<tr><td><code>Tensor::arange(5..10, device)</code></td><td><code>tensor.arange(start=5, end=10, device=device)</code></td></tr>
<tr><td><code>Tensor::arange_step(5..10, 2, device)</code></td><td><code>tensor.arange(start=5, end=10, step=2, device=device)</code></td></tr>
<tr><td><code>tensor.bitwise_and(other)</code></td><td><code>torch.bitwise_and(tensor, other)</code></td></tr>
<tr><td><code>tensor.bitwise_and_scalar(scalar)</code></td><td><code>torch.bitwise_and(tensor, scalar)</code></td></tr>
<tr><td><code>tensor.bitwise_not()</code></td><td><code>torch.bitwise_not(tensor)</code></td></tr>
<tr><td><code>tensor.bitwise_left_shift(other)</code></td><td><code>torch.bitwise_left_shift(tensor, other)</code></td></tr>
<tr><td><code>tensor.bitwise_left_shift_scalar(scalar)</code></td><td><code>torch.bitwise_left_shift(tensor, scalar)</code></td></tr>
<tr><td><code>tensor.bitwise_right_shift(other)</code></td><td><code>torch.bitwise_right_shift(tensor, other)</code></td></tr>
<tr><td><code>tensor.bitwise_right_shift_scalar(scalar)</code></td><td><code>torch.bitwise_right_shift(tensor, scalar)</code></td></tr>
<tr><td><code>tensor.bitwise_or(other)</code></td><td><code>torch.bitwise_or(tensor, other)</code></td></tr>
<tr><td><code>tensor.bitwise_or_scalar(scalar)</code></td><td><code>torch.bitwise_or(tensor, scalar)</code></td></tr>
<tr><td><code>tensor.bitwise_xor(other)</code></td><td><code>torch.bitwise_xor(tensor, other)</code></td></tr>
<tr><td><code>tensor.bitwise_xor_scalar(scalar)</code></td><td><code>torch.bitwise_xor(tensor, scalar)</code></td></tr>
<tr><td><code>tensor.float()</code></td><td><code>tensor.to(torch.float)</code></td></tr>
<tr><td><code>tensor.from_ints(ints)</code></td><td>N/A</td></tr>
<tr><td><code>tensor.int_random(shape, distribution, device)</code></td><td>N/A</td></tr>
<tr><td><code>tensor.cartesian_grid(shape, device)</code></td><td>N/A</td></tr>
</tbody></table>
</div>
<h3 id="bool-operations"><a class="header" href="#bool-operations">Bool Operations</a></h3>
<p>Those operations are only available for <code>Bool</code> tensors.</p>
<div class="table-wrapper"><table><thead><tr><th>Mabor API</th><th>PyTorch Equivalent</th></tr></thead><tbody>
<tr><td><code>Tensor::diag_mask(shape, diagonal)</code></td><td>N/A</td></tr>
<tr><td><code>Tensor::tril_mask(shape, diagonal)</code></td><td>N/A</td></tr>
<tr><td><code>Tensor::triu_mask(shape, diagonal)</code></td><td>N/A</td></tr>
<tr><td><code>tensor.argwhere()</code></td><td><code>tensor.argwhere()</code></td></tr>
<tr><td><code>tensor.bool_and()</code></td><td><code>tensor.logical_and()</code></td></tr>
<tr><td><code>tensor.bool_not()</code></td><td><code>tensor.logical_not()</code></td></tr>
<tr><td><code>tensor.bool_or()</code></td><td><code>tensor.logical_or()</code></td></tr>
<tr><td><code>tensor.float()</code></td><td><code>tensor.to(torch.float)</code></td></tr>
<tr><td><code>tensor.int()</code></td><td><code>tensor.to(torch.long)</code></td></tr>
<tr><td><code>tensor.nonzero()</code></td><td><code>tensor.nonzero(as_tuple=True)</code></td></tr>
</tbody></table>
</div>
<h3 id="quantization-operations"><a class="header" href="#quantization-operations">Quantization Operations</a></h3>
<p>Those operations are only available for <code>Float</code> tensors on backends that implement quantization
strategies.</p>
<div class="table-wrapper"><table><thead><tr><th>Mabor API</th><th>PyTorch Equivalent</th></tr></thead><tbody>
<tr><td><code>tensor.quantize(scheme, qparams)</code></td><td>N/A</td></tr>
<tr><td><code>tensor.dequantize()</code></td><td>N/A</td></tr>
</tbody></table>
</div>
<h2 id="activation-functions"><a class="header" href="#activation-functions">Activation Functions</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Mabor API</th><th>PyTorch Equivalent</th></tr></thead><tbody>
<tr><td><code>activation::gelu(tensor)</code></td><td><code>nn.functional.gelu(tensor)</code></td></tr>
<tr><td><code>activation::hard_sigmoid(tensor, alpha, beta)</code></td><td><code>nn.functional.hardsigmoid(tensor)</code></td></tr>
<tr><td><code>activation::leaky_relu(tensor, negative_slope)</code></td><td><code>nn.functional.leaky_relu(tensor, negative_slope)</code></td></tr>
<tr><td><code>activation::log_sigmoid(tensor)</code></td><td><code>nn.functional.log_sigmoid(tensor)</code></td></tr>
<tr><td><code>activation::log_softmax(tensor, dim)</code></td><td><code>nn.functional.log_softmax(tensor, dim)</code></td></tr>
<tr><td><code>activation::mish(tensor)</code></td><td><code>nn.functional.mish(tensor)</code></td></tr>
<tr><td><code>activation::prelu(tensor,alpha)</code></td><td><code>nn.functional.prelu(tensor,weight)</code></td></tr>
<tr><td><code>activation::quiet_softmax(tensor, dim)</code></td><td><code>nn.functional.quiet_softmax(tensor, dim)</code></td></tr>
<tr><td><code>activation::relu(tensor)</code></td><td><code>nn.functional.relu(tensor)</code></td></tr>
<tr><td><code>activation::sigmoid(tensor)</code></td><td><code>nn.functional.sigmoid(tensor)</code></td></tr>
<tr><td><code>activation::silu(tensor)</code></td><td><code>nn.functional.silu(tensor)</code></td></tr>
<tr><td><code>activation::softmax(tensor, dim)</code></td><td><code>nn.functional.softmax(tensor, dim)</code></td></tr>
<tr><td><code>activation::softmin(tensor, dim)</code></td><td><code>nn.functional.softmin(tensor, dim)</code></td></tr>
<tr><td><code>activation::softplus(tensor, beta)</code></td><td><code>nn.functional.softplus(tensor, beta)</code></td></tr>
<tr><td><code>activation::tanh(tensor)</code></td><td><code>nn.functional.tanh(tensor)</code></td></tr>
</tbody></table>
</div>
<h2 id="grid-functions"><a class="header" href="#grid-functions">Grid Functions</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Mabor API</th><th>PyTorch Equivalent</th></tr></thead><tbody>
<tr><td><code>grid::meshgrid(tensors, GridIndexing::Matrix)</code></td><td>`torch.meshgrid(tensors, indexing="ij")</td></tr>
<tr><td><code>grid::meshgrid(tensors, GridIndexing::Cartesian)</code></td><td>`torch.meshgrid(tensors, indexing="xy")</td></tr>
</tbody></table>
</div>
<h2 id="linalg-functions"><a class="header" href="#linalg-functions">Linalg Functions</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Mabor API</th><th>PyTorch Equivalent</th></tr></thead><tbody>
<tr><td><code>linalg::vector_norm(tensors, p, dim)</code></td><td>`torch.linalg.vector_norm(tensor, p, dim)</td></tr>
</tbody></table>
</div>
<h2 id="displaying-tensor-details"><a class="header" href="#displaying-tensor-details">Displaying Tensor Details</a></h2>
<p>Mabor provides flexible options for displaying tensor information, allowing you to control the level
of detail and formatting to suit your needs.</p>
<h3 id="basic-display"><a class="header" href="#basic-display">Basic Display</a></h3>
<p>To display a detailed view of a tensor, you can simply use Rust's <code>println!</code> or <code>format!</code> macros:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let tensor = Tensor::&lt;Backend, 2&gt;::full([2, 3], 0.123456789, &amp;Default::default());
println!("{}", tensor);
<span class="boring">}</span></code></pre></pre>
<p>This will output:</p>
<pre><code>Tensor {
  data:
[[0.12345679, 0.12345679, 0.12345679],
 [0.12345679, 0.12345679, 0.12345679]],
  shape:  [2, 3],
  device:  Cpu,
  backend:  "ndarray",
  kind:  "Float",
  dtype:  "f32",
}
</code></pre>
<h3 id="controlling-precision"><a class="header" href="#controlling-precision">Controlling Precision</a></h3>
<p>You can control the number of decimal places displayed using Rust's formatting syntax:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>println!("{:.2}", tensor);
<span class="boring">}</span></code></pre></pre>
<p>Output:</p>
<pre><code>Tensor {
  data:
[[0.12, 0.12, 0.12],
 [0.12, 0.12, 0.12]],
  shape:  [2, 3],
  device:  Cpu,
  backend:  "ndarray",
  kind:  "Float",
  dtype:  "f32",
}
</code></pre>
<h3 id="global-print-options"><a class="header" href="#global-print-options">Global Print Options</a></h3>
<p>For more fine-grained control over tensor printing, Mabor provides a <code>PrintOptions</code> struct and a
<code>set_print_options</code> function:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mabor::tensor::{set_print_options, PrintOptions};

let print_options = PrintOptions {
    precision: Some(2),
    ..Default::default()
};

set_print_options(print_options);
<span class="boring">}</span></code></pre></pre>
<p>Options:</p>
<ul>
<li>
<p><code>precision</code>: Number of decimal places for floating-point numbers (default: None)</p>
</li>
<li>
<p><code>threshold</code>: Maximum number of elements to display before summarizing (default: 1000)</p>
</li>
<li>
<p><code>edge_items</code>: Number of items to show at the beginning and end of each dimension when summarizing
(default: 3)</p>
<h3 id="checking-tensor-closeness"><a class="header" href="#checking-tensor-closeness">Checking Tensor Closeness</a></h3>
<p>Mabor provides a utility function <code>check_closeness</code> to compare two tensors and assess their
similarity. This function is particularly useful for debugging and validating tensor operations,
especially when working with floating-point arithmetic where small numerical differences can
accumulate. It's also valuable when comparing model outputs during the process of importing models
from other frameworks, helping to ensure that the imported model produces results consistent with
the original.</p>
<p>Here's an example of how to use <code>check_closeness</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mabor::tensor::{check_closeness, Tensor};
type B = mabor::backend::NdArray;

let device = Default::default();
let tensor1 = Tensor::&lt;B, 1&gt;::from_floats(
    [1.0, 2.0, 3.0, 4.0, 5.0, 6.001, 7.002, 8.003, 9.004, 10.1],
    &amp;device,
);
let tensor2 = Tensor::&lt;B, 1&gt;::from_floats(
    [1.0, 2.0, 3.0, 4.000, 5.0, 6.0, 7.001, 8.002, 9.003, 10.004],
    &amp;device,
);

check_closeness(&amp;tensor1, &amp;tensor2);
<span class="boring">}</span></code></pre></pre>
<p>The <code>check_closeness</code> function compares the two input tensors element-wise, checking their
absolute differences against a range of epsilon values. It then prints a detailed report showing
the percentage of elements that are within each tolerance level.</p>
<p>The output provides a breakdown for different epsilon values, allowing you to assess the closeness
of the tensors at various precision levels. This is particularly helpful when dealing with
operations that may introduce small numerical discrepancies.</p>
<p>The function uses color-coded output to highlight the results:</p>
<ul>
<li>Green [PASS]: All elements are within the specified tolerance.</li>
<li>Yellow [WARN]: Most elements (90% or more) are within tolerance.</li>
<li>Red [FAIL]: Significant differences are detected.</li>
</ul>
<p>This utility can be invaluable when implementing or debugging tensor operations, especially those
involving complex mathematical computations or when porting algorithms from other frameworks. It's
also an essential tool when verifying the accuracy of imported models, ensuring that the Mabor
implementation produces results that closely match those of the original model.</p>
</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="backend.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="autodiff.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="backend.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="autodiff.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->



    </div>
    </body>
</html>
