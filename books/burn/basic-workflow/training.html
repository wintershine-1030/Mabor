<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Training - The Burn Book 🔥</title>


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="../highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="../tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->

        <!-- MathJax -->
        <script async="" src="../../../ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "../";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "../searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">The Burn Book 🔥</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="training"><a class="header" href="#training">Training</a></h1>
<p>We are now ready to write the necessary code to train our model on the MNIST dataset. We shall
define the code for this training section in the file: <code>src/training.rs</code>.</p>
<p>Instead of a simple tensor, the model should output an item that can be understood by the learner, a
struct whose responsibility is to apply an optimizer to the model. The output struct is used for all
metrics calculated during the training. Therefore it should include all the necessary information to
calculate any metric that you want for a task.</p>
<p>Burn provides two basic output types: <code>ClassificationOutput</code> and <code>RegressionOutput</code>. They implement
the necessary trait to be used with metrics. It is possible to create your own item, but it is
beyond the scope of this guide.</p>
<p>Since the MNIST task is a classification problem, we will use the <code>ClassificationOutput</code> type.</p>
<pre><code class="language-rust   ignore"><span class="boring">use crate::{
</span><span class="boring">    data::{MnistBatch, MnistBatcher},
</span><span class="boring">    model::{Model, ModelConfig},
</span><span class="boring">};
</span><span class="boring">use burn::{
</span><span class="boring">    data::{dataloader::DataLoaderBuilder, dataset::vision::MnistDataset},
</span><span class="boring">    nn::loss::CrossEntropyLossConfig,
</span><span class="boring">    optim::AdamConfig,
</span><span class="boring">    prelude::*,
</span><span class="boring">    record::CompactRecorder,
</span><span class="boring">    tensor::backend::AutodiffBackend,
</span><span class="boring">    train::{
</span><span class="boring">        metric::{AccuracyMetric, LossMetric},
</span><span class="boring">        ClassificationOutput, LearnerBuilder, TrainOutput, TrainStep, ValidStep,
</span><span class="boring">    },
</span><span class="boring">};
</span><span class="boring">
</span>impl&lt;B: Backend&gt; Model&lt;B&gt; {
    pub fn forward_classification(
        &amp;self,
        images: Tensor&lt;B, 3&gt;,
        targets: Tensor&lt;B, 1, Int&gt;,
    ) -&gt; ClassificationOutput&lt;B&gt; {
        let output = self.forward(images);
        let loss = CrossEntropyLossConfig::new()
            .init(&amp;output.device())
            .forward(output.clone(), targets.clone());

        ClassificationOutput::new(loss, output, targets)
    }
}</code></pre>
<p>As evident from the preceding code block, we employ the cross-entropy loss module for loss
calculation, without the inclusion of any padding token. We then return the classification output
containing the loss, the output tensor with all logits and the targets.</p>
<p>Please take note that tensor operations receive owned tensors as input. For reusing a tensor
multiple times, you need to use the <code>clone()</code> function. There's no need to worry; this process won't
involve actual copying of the tensor data. Instead, it will simply indicate that the tensor is
employed in multiple instances, implying that certain operations won't be performed in place. In
summary, our API has been designed with owned tensors to optimize performance.</p>
<p>Moving forward, we will proceed with the implementation of both the training and validation steps
for our model.</p>
<pre><code class="language-rust   ignore"><span class="boring">use crate::{
</span><span class="boring">    data::{MnistBatch, MnistBatcher},
</span><span class="boring">    model::{Model, ModelConfig},
</span><span class="boring">};
</span><span class="boring">use burn::{
</span><span class="boring">    data::{dataloader::DataLoaderBuilder, dataset::vision::MnistDataset},
</span><span class="boring">    nn::loss::CrossEntropyLossConfig,
</span><span class="boring">    optim::AdamConfig,
</span><span class="boring">    prelude::*,
</span><span class="boring">    record::CompactRecorder,
</span><span class="boring">    tensor::backend::AutodiffBackend,
</span><span class="boring">    train::{
</span><span class="boring">        metric::{AccuracyMetric, LossMetric},
</span><span class="boring">        ClassificationOutput, LearnerBuilder, TrainOutput, TrainStep, ValidStep,
</span><span class="boring">    },
</span><span class="boring">};
</span><span class="boring">
</span><span class="boring">impl&lt;B: Backend&gt; Model&lt;B&gt; {
</span><span class="boring">    pub fn forward_classification(
</span><span class="boring">        &amp;self,
</span><span class="boring">        images: Tensor&lt;B, 3&gt;,
</span><span class="boring">        targets: Tensor&lt;B, 1, Int&gt;,
</span><span class="boring">    ) -&gt; ClassificationOutput&lt;B&gt; {
</span><span class="boring">        let output = self.forward(images);
</span><span class="boring">        let loss = CrossEntropyLossConfig::new()
</span><span class="boring">            .init(&amp;output.device())
</span><span class="boring">            .forward(output.clone(), targets.clone());
</span><span class="boring">
</span><span class="boring">        ClassificationOutput::new(loss, output, targets)
</span><span class="boring">    }
</span><span class="boring">}
</span><span class="boring">
</span>impl&lt;B: AutodiffBackend&gt; TrainStep&lt;MnistBatch&lt;B&gt;, ClassificationOutput&lt;B&gt;&gt; for Model&lt;B&gt; {
    fn step(&amp;self, batch: MnistBatch&lt;B&gt;) -&gt; TrainOutput&lt;ClassificationOutput&lt;B&gt;&gt; {
        let item = self.forward_classification(batch.images, batch.targets);

        TrainOutput::new(self, item.loss.backward(), item)
    }
}

impl&lt;B: Backend&gt; ValidStep&lt;MnistBatch&lt;B&gt;, ClassificationOutput&lt;B&gt;&gt; for Model&lt;B&gt; {
    fn step(&amp;self, batch: MnistBatch&lt;B&gt;) -&gt; ClassificationOutput&lt;B&gt; {
        self.forward_classification(batch.images, batch.targets)
    }
}</code></pre>
<p>Here we define the input and output types as generic arguments in the <code>TrainStep</code> and <code>ValidStep</code>.
We will call them <code>MnistBatch</code> and <code>ClassificationOutput</code>. In the training step, the computation of
gradients is straightforward, necessitating a simple invocation of <code>backward()</code> on the loss. Note
that contrary to PyTorch, gradients are not stored alongside each tensor parameter, but are rather
returned by the backward pass, as such: <code>let gradients = loss.backward();</code>. The gradient of a
parameter can be obtained with the grad function: <code>let grad = tensor.grad(&amp;gradients);</code>. Although it
is not necessary when using the learner struct and the optimizers, it can prove to be quite useful
when debugging or writing custom training loops. One of the differences between the training and the
validation steps is that the former requires the backend to implement <code>AutodiffBackend</code> and not just
<code>Backend</code>. Otherwise, the <code>backward</code> function is not available, as the backend does not support
autodiff. We will see later how to create a backend with autodiff support.</p>
<details>
<summary><strong>🦀 Generic Type Constraints in Method Definitions</strong></summary>
<p>Although generic data types, trait and trait bounds were already introduced in previous sections of
this guide, the previous code snippet might be a lot to take in at first.</p>
<p>In the example above, we implement the <code>TrainStep</code> and <code>ValidStep</code> trait for our <code>Model</code> struct,
which is generic over the <code>Backend</code> trait as has been covered before. These traits are provided by
<code>burn::train</code> and define a common <code>step</code> method that should be implemented for all structs. Since
the trait is generic over the input and output types, the trait implementation must specify the
concrete types used. This is where the additional type constraints appear
<code>&lt;MnistBatch&lt;B&gt;, ClassificationOutput&lt;B&gt;&gt;</code>. As we saw previously, the concrete input type for the
batch is <code>MnistBatch</code>, and the output of the forward pass is <code>ClassificationOutput</code>. The <code>step</code>
method signature matches the concrete input and output types.</p>
<p>For more details specific to constraints on generic types when defining methods, take a look at
<a href="https://doc.rust-lang.org/book/ch10-01-syntax.html#in-method-definitions">this section</a> of the Rust
Book.</p>
</details><br>
<p>Let us move on to establishing the practical training configuration.</p>
<pre><code class="language-rust   ignore"><span class="boring">use crate::{
</span><span class="boring">    data::{MnistBatch, MnistBatcher},
</span><span class="boring">    model::{Model, ModelConfig},
</span><span class="boring">};
</span><span class="boring">use burn::{
</span><span class="boring">    data::{dataloader::DataLoaderBuilder, dataset::vision::MnistDataset},
</span><span class="boring">    nn::loss::CrossEntropyLossConfig,
</span><span class="boring">    optim::AdamConfig,
</span><span class="boring">    prelude::*,
</span><span class="boring">    record::CompactRecorder,
</span><span class="boring">    tensor::backend::AutodiffBackend,
</span><span class="boring">    train::{
</span><span class="boring">        metric::{AccuracyMetric, LossMetric},
</span><span class="boring">        ClassificationOutput, LearnerBuilder, TrainOutput, TrainStep, ValidStep,
</span><span class="boring">    },
</span><span class="boring">};
</span><span class="boring">
</span><span class="boring">impl&lt;B: Backend&gt; Model&lt;B&gt; {
</span><span class="boring">    pub fn forward_classification(
</span><span class="boring">        &amp;self,
</span><span class="boring">        images: Tensor&lt;B, 3&gt;,
</span><span class="boring">        targets: Tensor&lt;B, 1, Int&gt;,
</span><span class="boring">    ) -&gt; ClassificationOutput&lt;B&gt; {
</span><span class="boring">        let output = self.forward(images);
</span><span class="boring">        let loss = CrossEntropyLossConfig::new()
</span><span class="boring">            .init(&amp;output.device())
</span><span class="boring">            .forward(output.clone(), targets.clone());
</span><span class="boring">
</span><span class="boring">        ClassificationOutput::new(loss, output, targets)
</span><span class="boring">    }
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">impl&lt;B: AutodiffBackend&gt; TrainStep&lt;MnistBatch&lt;B&gt;, ClassificationOutput&lt;B&gt;&gt; for Model&lt;B&gt; {
</span><span class="boring">    fn step(&amp;self, batch: MnistBatch&lt;B&gt;) -&gt; TrainOutput&lt;ClassificationOutput&lt;B&gt;&gt; {
</span><span class="boring">        let item = self.forward_classification(batch.images, batch.targets);
</span><span class="boring">
</span><span class="boring">        TrainOutput::new(self, item.loss.backward(), item)
</span><span class="boring">    }
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">impl&lt;B: Backend&gt; ValidStep&lt;MnistBatch&lt;B&gt;, ClassificationOutput&lt;B&gt;&gt; for Model&lt;B&gt; {
</span><span class="boring">    fn step(&amp;self, batch: MnistBatch&lt;B&gt;) -&gt; ClassificationOutput&lt;B&gt; {
</span><span class="boring">        self.forward_classification(batch.images, batch.targets)
</span><span class="boring">    }
</span><span class="boring">}
</span><span class="boring">
</span>#[derive(Config)]
pub struct TrainingConfig {
    pub model: ModelConfig,
    pub optimizer: AdamConfig,
    #[config(default = 10)]
    pub num_epochs: usize,
    #[config(default = 64)]
    pub batch_size: usize,
    #[config(default = 4)]
    pub num_workers: usize,
    #[config(default = 42)]
    pub seed: u64,
    #[config(default = 1.0e-4)]
    pub learning_rate: f64,
}

fn create_artifact_dir(artifact_dir: &amp;str) {
    // Remove existing artifacts before to get an accurate learner summary
    std::fs::remove_dir_all(artifact_dir).ok();
    std::fs::create_dir_all(artifact_dir).ok();
}

pub fn train&lt;B: AutodiffBackend&gt;(artifact_dir: &amp;str, config: TrainingConfig, device: B::Device) {
    create_artifact_dir(artifact_dir);
    config
        .save(format!("{artifact_dir}/config.json"))
        .expect("Config should be saved successfully");

    B::seed(config.seed);

    let batcher = MnistBatcher::default();

    let dataloader_train = DataLoaderBuilder::new(batcher.clone())
        .batch_size(config.batch_size)
        .shuffle(config.seed)
        .num_workers(config.num_workers)
        .build(MnistDataset::train());

    let dataloader_test = DataLoaderBuilder::new(batcher)
        .batch_size(config.batch_size)
        .shuffle(config.seed)
        .num_workers(config.num_workers)
        .build(MnistDataset::test());

    let learner = LearnerBuilder::new(artifact_dir)
        .metric_train_numeric(AccuracyMetric::new())
        .metric_valid_numeric(AccuracyMetric::new())
        .metric_train_numeric(LossMetric::new())
        .metric_valid_numeric(LossMetric::new())
        .with_file_checkpointer(CompactRecorder::new())
        .devices(vec![device.clone()])
        .num_epochs(config.num_epochs)
        .summary()
        .build(
            config.model.init::&lt;B&gt;(&amp;device),
            config.optimizer.init(),
            config.learning_rate,
        );

    let model_trained = learner.fit(dataloader_train, dataloader_test);

    model_trained
        .save_file(format!("{artifact_dir}/model"), &amp;CompactRecorder::new())
        .expect("Trained model should be saved successfully");
}</code></pre>
<p>It is a good practice to use the <code>Config</code> derive to create the experiment configuration. In the
<code>train</code> function, the first thing we are doing is making sure the <code>artifact_dir</code> exists, using the
standard rust library for file manipulation. All checkpoints, logging and metrics will be stored
under this directory. We initialize the dataloaders using the previously created batcher. Since no
automatic differentiation is needed during the validation phase, the <code>learner.fit(...)</code> method
defines the necessary backend bounds on the data loader for <code>B::InnerBackend</code> (see
<a href="backend.html">Backend</a>). The autodiff capabilities are available through a type system, making it
nearly impossible to forget to deactivate gradient calculation.</p>
<p>Next, we create our learner with the accuracy and loss metric on both training and validation steps
along with the device and the epoch. We also configure the checkpointer using the <code>CompactRecorder</code>
to indicate how weights should be stored. This struct implements the <code>Recorder</code> trait, which makes
it capable of saving records for persistency.</p>
<p>We then build the learner with the model, the optimizer and the learning rate. Notably, the third
argument of the build function should actually be a learning rate <em>scheduler</em>. When provided with a
float as in our example, it is automatically transformed into a <em>constant</em> learning rate scheduler.
The learning rate is not part of the optimizer config as it is often done in other frameworks, but
rather passed as a parameter when executing the optimizer step. This avoids having to mutate the
state of the optimizer and is therefore more functional. It makes no difference when using the
learner struct, but it will be an essential nuance to grasp if you implement your own training loop.</p>
<p>Once the learner is created, we can simply call <code>fit</code> and provide the training and validation
dataloaders. For the sake of simplicity in this example, we employ the test set as the validation
set; however, we do not recommend this practice for actual usage.</p>
<p>Finally, the trained model is returned by the <code>fit</code> method. The trained weights are then saved using
the <code>CompactRecorder</code>. This recorder employs the <code>MessagePack</code> format with half precision, <code>f16</code> for
floats and <code>i16</code> for integers. Other recorders are available, offering support for various formats,
such as <code>BinCode</code> and <code>JSON</code>, with or without compression. Any backend, regardless of precision, can
load recorded data of any kind.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="data.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="backend.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="data.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="backend.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->



    </div>
    </body>
</html>
